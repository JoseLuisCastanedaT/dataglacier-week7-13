{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fde817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ee9b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet\n",
       "id                                                          \n",
       "1       0   @user when a father is dysfunctional and is s...\n",
       "2       0  @user @user thanks for #lyft credit i can't us...\n",
       "3       0                                bihday your majesty\n",
       "4       0  #model   i love u take with u all the time in ...\n",
       "5       0             factsguide: society now    #motivation\n",
       "6       0  [2/2] huge fan fare and big talking before the...\n",
       "7       0   @user camping tomorrow @user @user @user @use...\n",
       "8       0  the next school year is the year for exams.ð...\n",
       "9       0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "10      0   @user @user welcome here !  i'm   it's so #gr...\n",
       "11      0   â #ireland consumer price index (mom) climb...\n",
       "12      0  we are so selfish. #orlando #standwithorlando ...\n",
       "13      0  i get to see my daddy today!!   #80days #getti...\n",
       "14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "15      1  no comment!  in #australia   #opkillingbay #se...\n",
       "16      0  ouch...junior is angryð#got7 #junior #yugyo...\n",
       "17      0  i am thankful for having a paner. #thankful #p...\n",
       "18      1                             retweet if you agree! \n",
       "19      0  its #friday! ð smiles all around via ig use...\n",
       "20      0  as we all know, essential oils are not made of..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading data\n",
    "\n",
    "df_train = pd.read_csv('tweets_hate_speech_transformers/train_E6oV3lV.csv').set_index('id')\n",
    "\n",
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd71d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e1f165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1     father dysfunctional selfish drag kid dysfunct...\n",
       "2     thanks lyft credit cant use cause dont offer w...\n",
       "3                                        bihday majesty\n",
       "4                           model love u take u time ur\n",
       "5                         factsguide society motivation\n",
       "6     huge fan fare big talking leave chaos pay disp...\n",
       "7                               camping tomorrow dannya\n",
       "8     next school year year exam cant think school e...\n",
       "9     love land allin cavs champion cleveland clevel...\n",
       "10                                        welcome im gr\n",
       "11    ireland consumer price index mom climbed previ...\n",
       "12    selfish orlando standwithorlando pulseshooting...\n",
       "13                   get see daddy today day gettingfed\n",
       "14    cnn call michigan middle school build wall cha...\n",
       "15    comment australia opkillingbay seashepherd hel...\n",
       "16              ouchjunior angry got junior yugyoem omg\n",
       "17                     thankful paner thankful positive\n",
       "18                                        retweet agree\n",
       "19    friday smile around via ig user cooky make people\n",
       "20                     know essential oil made chemical\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning the tweets\n",
    "\n",
    "import re, emoji\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from unicodedata import normalize\n",
    "\n",
    "def cleaner(tweet):\n",
    "    tweet = \"\".join(u for u in tweet if u not in (\"?\", \".\", \",\", \";\", \":\", \"!\", '\"', \"'\", \"¡\", \"¿\"))\n",
    "    tweet = re.sub(r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", normalize( \"NFD\", tweet), 0, re.I)\n",
    "    tweet = normalize( 'NFC', tweet) #Esta linea y la anterior transforma á -> a, é -> e ....\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet).split()) #Removes the @user\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z]\", \" \", str(tweet).lower())\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    token = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop = stopwords.words(\"english\")\n",
    "    words = [t for t in token if t not in stop]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lem = \" \".join(temp for temp in [WordNetLemmatizer().lemmatize(w) for w in words])\n",
    "    \n",
    "    return lem\n",
    "\n",
    "df_train['tweet'] = df_train['tweet'].map(lambda x: cleaner(x))\n",
    "df_train['tweet'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04976a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of stopwords\n",
    "stopwords.words(\"english\")[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710bcc1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14561a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
